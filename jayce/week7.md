# Auto Scaling

### Auto Scaling 이란?
미리 정해 놓은 규칙에 따라 워크로드를 자동으로 확대 또는 축소 할 수 있는 기술이다.

### Auto Scaling의 장점

#### 동적 스케일링
사용자의 요구 수준에 따라 리소스를 동적으로 스케일링 할 수 있다는 장점이 있다. 스케일업 할 수 있는 서버의 수에는 제한이 없고,
필요한 경우 서버 두 대에서 수백 대, 수천대 등 즉시 스케일업 할 수 있다. 

#### 최상의 사용자 경험 및 성능 향상
Auto Scaling을 이용하면 리소스가 항상 적정 수준에서 제공되고 애플리케이션은 항상 최적의 상태에서 실행되므로
애플리케이션 사용자에게 최상의 사용자 경험을 제공할 수 있다.

#### 헬스 체크와 서버 플릿 관리
Auto Scaling을 이용하면 EC2 인스턴스의 헬스 체크 상태를 모니터링 할 수 있다.
헬스 체크를 하는 과정에서 특정 인스턴스의 문제가 감지되면, 자동으로 다른 인스턴스로 교체한다.
또한 적정 수준의 서버 플릿 용량을 유지하는 데도 도움을 준다.

##### 서버 플릿 이란?
다수의 EC2 서버에서 애플리케이션을 호스팅하는 경우 이들 일련의 EC2 서버 집합을 서버 플릿이라 부른다.

##### ELB에서의 Auto Scaling
ELB로 AutoScaling을 설정하는 경우 ELB의 헬스 체크 기능도 사용할 수 있다.

#### 로드 밸런싱
Auto Scaling은 리소스를 동적으로 스케일업 또는 스케일 다운한다.
ELB와 함께 사용하면 다수의 EC2 인스턴스에게 워크로드를 효과적으로 분배 할 수 있고, 다수의 AZ에 분포된 EC2
인스턴스에 대한 워크로드도 자동으로 분배하도록 설정할 수 있다.

#### 타깃 트래킹
사용자는 특정 타깃에 대해서만 Auto Scaling을 할 수 있으며, 사용자가 설정한 타깃에 맞춰 EC2 인스턴스의 수를 조정한다.
예를 들어, Auto Scaling 타깃으로 애플리케이션 서버의 CPU 사용률을 65%로 설정하면 활용률에 맞춰 인스턴스 수를 자동으로 조정한다.

#### 리소스 비용 관리
Auto Scaling을 이용하면 불필요한 리소스를 자동으로 제거해 예산 낭비를 막을 수 있다.

#### 예측적 확장
Auto Scaling은 머신러닝과 통합됐으며, ML Auto Scaling을 이용해서 수요 예측치에 근거, 
컴퓨트 용량을 자동으로 확장 또는 축소할 수 있다.

### EC2 외에 사용되는 Auto Scaling

- EC2 스팟 인스턴스
- EC2 Container Service(ECS)
- Elastic Map Reducer(EMR) 클러스터
- AppStream 2.0 인스턴스
- Amazon Aurora Replicas
- DynamoDb

## 리소스 확장 및 축소 계획 수립
Auto Scaling 활용의 첫 번째 단계는 리소스 확장 및 축소 계획을 수립하는 것이다.

### 확장 가능한 리소스 파악

#### 스택을 통한 검색(CloudFormation)
기존의 AWS CloudFormation 스택을 이용해 자동화된 스케일링 환경 설정이 가능한 리소스를 찾아낼 수 있다.

#### 태그를 기준으로 한 검색
리소스를 찾을 때는 태그도 이용할 수 있다.
- Aurora DB 클러스터
- Auto Scaling 그룹
- DynamoDB 테이블과 전역 보조 인덱스

#### EC2 Auto Scaling 그룹
스케일링 계획에 하나 이상의 Auto Scaling 그룹을 선택해서 추가할 수 있다.

### 리소스 확장 전략 구체화
Auto Scaling을 적용할 리소스 파악 후 스케일업, 스케일 다운 전략을 설정한다

#### 리소스 스케일링 전략

##### 가용성 기준 최적화
이 옵션은 가용성 기준에 맞춰 자동으로 스케일업 또는 스케일 다운 작업을 시행한다.
이 옵션에서 Auto Scaling은 CPU/리소스 활성화 수준을 40퍼센트로 맞춘다.

##### 가용성과 비용의 균영
이 옵션을 선택하면 가용성과 비용의 균형에 초점을 맞춰서 리소스 확장 여보를 결정한다.
이 옵션에서 Auto Scaling은 CPU/리소스 활성화 수준을 50퍼센트로 설정해 가용성과 비용의 균형을 맞춘다.

##### 비용 기준 최적화
이 옵션의 목적은 비용을 낮추는 것이다.
이 옵션에서 Auto Scaling은 CPU/리소스 활성화 수준을 70퍼센트로 설정하며, 성능에 중요성이 높지 않은 로우레벨 환경에 적합하다

##### 커스텀 스케일링 전략
이 옵션을 선택하면 Auto Scaling은 원하는 지표에 따라 리소스 확장 여부를 결정할 수 있다.

##### 예측적 스케일링 전략
이 옵션은 머신러닝이 과거의 워크로드 처리 유형을 분석하고 미래의 워크로드 유형을 예측한다.

##### 동적 스케일링 전략
스케일링 계획에 포함된 리소스에 대한 목표 추적 스케일링 정책을 생성해 리소스 확장을 관리한다.
예를 들어, EC2 서버의 CPU 성능을 60퍼센트로 제한해 사용하다가 기준치를 초과하면 리소스 확장과 관련된 스케일링 정책이 실행되게 할 수 있다.

## EC2 Auto Scaling 활용

### 실행 환경 설정
Auto Scaling으로 인스턴스를 확장 또는 축소하려면 먼저 어떤 서버를 사용할지 결정해야 한다.
이를 실행 환경 설정에서 할 수 있는데, 실행 환경 설정은 일종의 템플릿으로 AMI 상세정보, 인스턴스 타입, 키 페어 등
인스턴스에 대한 모든 정보를 담고 있다. 실행 환경 설정 템플릿을 생성한 뒤에 이를 Auto Scaling 그룹에 연결 할 수 있다.

#### 실행 환경 설정 특징

- Auto Scaling 그룹은 항상 하나의 실행 환경 설정 템플릿만 지닐 수 있다.
- Auto Scaling 그룹을 생성한 뒤에는 이와 연결된 실행 환경 설정을 수정 할 수 없다.
- 인스턴스를 다시 실행하면 새 Auto Scaling 그룹의 내용이 적용 된다.

### Auto Scaling 그룹
Auto Scaling 그룹은 스케일업 및 스케일다운 규칙의 모음으로 EC2 인스턴스의 시작부터 삭제까지의 모든 동작에 대한 규칙과 정책을 담고 있다.

#### 스케일링 유형

##### 인스턴스 레벨 유지
기본 스케일링 계획으로도 부르며, 항상 실행 상태를 유지하고자 하는 인스턴스의 수를 정의 할 수 있다.
Auto Scaling 그룹은 해당 숫자 만큼의 인스턴스를 항상 실행한다.

##### 수동 스케일링
콘솔이나 API, CLI등을 이용해 수동으로 스케일링 작업을 수행할 수 있다. 수동 스케일링을 선택하면 사용자가 직접 인스턴스를 추가 또는 삭제 해야 한다.
스케일 자동화라는 Auto Scaling의 기본 취지를 생각하면 수동 스케일링 방식은 추천하지 않는다.

##### 요구별 스케일링
시스템의 요구 수준에 맞추는 방식으로 CloudWatch가 모니터링하는 CPU, 디스크 쓰기와 읽기, 네트워크 유입과 유출 등 주요 지표를 바탕으로 요구 수준에 맞춰 스케일링 규칙을 정하는 방식이다.

##### 일정별 스케일링
트래픽의 변화를 예측할 수 있고, 특정 시간대에 어느 정도의 트래픽이 증가하는지 패턴을 파악하고 있다면, 일정별 스케일링을 사용하는 것이 좋다.

#### Auto Scaling 그룹 정의 방법
Auto Scaling 그룹을 생성할 때는 항상 실행해야 하는 최소한의 인스턴스 수를 정의 해야 하며, 스케일업 상황에서 추가할 최대 인스턴스 수 또한 정의해야 한다.

##### 이상적인 처리 성능
- 이상적인 처리 성능이 현재의 처리 성능보다 높은 경우, 인스턴스를 추가해 실행한다
- 이상적인 처리 성능이 현재의 처리 성능보다 낮은 경우, 추가된 인스턴스를 삭제한다.

#### Auto Scaling의 파악
Auto Scaling의 서버 수를 증가, 감소를 파악하는 방법으로는 Amazon SNS를 이용 할 수 있고 SNS 알림을 통해 Auto Scaling 그룹에게 스케일업 또는 스케일다운 시기를 알려줄 수 있다.

##### Amazon SNS
아마존 SNS는 HTTP, HTTPS, POST, 이메일은 물론 아마존 SQS의 메세지 큐 방식으로 알림을 보낼 수 있다.

#### Auto Scaling의 특징

- 사용자가 활용 할 수 있는 Auto Scaling 그룹의 수는 정해져 있다.
- Auto Scaling 그룹의 개수 제한은 병경이 가능하며, AWS 서포트 티켓을 이용해 추가할 수 있다.
- Auto Scaling 그룹은 특정 리전을 벗어날 수 없고, 오직 하나의 리전에서만 사용 할 수 있다.
- 하나의 리전에 있는 다수의 AZ에서는 사용이 가능하다.

### 스케일링 정책

#### 심플 스케일링
심플 스케일링 정책을 이용하면 단 하나의 스케일링 정책에 따라 스케일업 및 스케일다운 할 수 있다. 예를 들어 CPU 사용률이 50%를 넘으면 인스턴스를 추가한다.

#### 단계별 심플 스케일링
조금 더 세분화된 이벤트 대응 액션을 위해 사용한다. 예를 들어 CPU 사용률이 50%~60%에 있을 때 2개의 인스턴스를 추가하고 60%를 넘으면 4대의 인스턴스를 추가 하도록 한다.

#### 타깃 트래킹 스케일링 정책
타깃 트래킹 스케일링 정책을 이용해 동적으로 환경을 설정할 수 있다. 이때 미리 정의된 성능 지표를 이용하거나 커스텀 성능 지표를 만들어서 타깃 값으로 설정 할 수 있다.

#### 인스턴스 삭제 정책
스케일링 다운 정책이 반영되면 EC2 인스턴스가 삭제되는데, 이에 정책을 설정 할 수 있다. 이 삭제 정책은 어떤 인스턴스를 먼저 셧다운할 것인지 결정하는 것이다.

##### 삭제 정책

1. 서버플릿에서 가장 오랫동안 실행된 서버를 삭제한다.
2. 시간단위 과금이 임박한 서버를 삭제한다.
3. 실행 환경 설정 기간이 가장 긴 인스턴스를 삭제한다.

### 스케일링 정책에서의 처리 용량 변경

#### 정확한 용량
스케일링 정책 작성 시 증가 또는 감소시킬 정확한 용량을 정의할 수 있다.

#### 숫자 지정 용량 변경
숫자에 따라 현재의 용량을 증가 또는 감소시킬 수 있다.

#### 퍼센트 단위의 용량 변경
퍼센트 단위로 현재의 용량을 증가 또는 감소시킬 수 있다.

## Elastic Load Balancing
온프레미스 환경에서 로드 밸런서란 다수의 서버에 유입되는 트래픽을 분산시켜서 워크로드의 균형을 잡기 위한 하드웨어를 가리킨다.

### 쓰는 이유
현대적인 다수의 애플리케이션은 웹 서버 앞에 로드 밸런서를 배치해 트래픽을 분산시키고 워크로드의 균형을 맞추며 탄력성을 증대 시키기 위해 사용한다.

### 문제점
1. 로드 밸런서가 고장나면 연결된 애플리케이션에 대한 접속이 안된다.
2. 로드 밸런서 하드웨어에 대한 관리 업무가 복잡하고 많다.

### AWS에서의 ELB란?
온프레미스에서의 로드밸런서 문제점을 해결할 수있는 완전 관리형 서비스로 애플리케이션으로 유입되는 트래픽을 EC2 인스턴스에서 호스팅 되고 있는 다수의 서비스에 분산시킨다.

### AWS ELB의 장점

#### 탄력성
ELB는 자동적으로 확장하기 때문에 인스턴스 추가, 삭제를 위한 어떤 수작업도 필요하지 않다.

#### 통합성
ELB는 다양한 AWS 서비스와 통합해 사용할 수 있다. 예를 들어 Auto Scaling으로 ELB를 통합하면 EC2 인스턴스 확장성 관리 및 워크로드 분산 업무를 더 효율적으로 수행 할 수 있다.

#### 안전성
ELB는 통합 인증 관리, SSL 복호화, 포트 포워딩 등 다수의 보안 기능을 제공한다.

#### 고가용성
ELB는 최고 수준의 고가용성 아키텍처를 구현하는데 도움을 준다. ELB는 다수의 EC2 인스턴스, 컨테이너, IP 주소 간에 트래픽을 분산 시키며 여러 AZ에 트래픽을 분산시킬 수 있다.

#### 저렴함
ELB는 저렴하며 비용 효율적이다.

### 로드 밸런서의 유형

#### Network Load Balancer
Network Load Balancer(NLB)는 TCP 로드 밸런서라고도 부르며, OSI 모델의 레이어 4에서 작동한다.
NLB는 기본적으로 연결 기반 로드 밸런서로 EC2 인스턴스, 컨테이너, IP 주소 등의 연결을 관리한다. 
이들이 생성하는 모든 요청은 로드 밸런서를 통해 흘러가며, 로드 밸런서는 전달되는 패킷을 관리하고, 이를 백엔드로 전달하는 역할을 수행한다.
이때 패킷의 내용까지 확인하지는 않는다. 또한 NLB는 패킷 헤더를 수정하지는 않으므로 패킷의 내용을 바꾸거나 할 수는 없다.

#### Application Load Balancer
Application Load Balancer(ALB)는 OSI 모델의 레이어 7에 해당하며, HTTP와 HTTPS를 지원한다. 
애플리케이션으로부터 패키지가 전달되면, 헤더로 받은 뒤 어디로 전송할지 결정한다. 이 연결은 로드 밸런서에서 종료되고 전달 내용은 연결 풀 형태로 모여있다가 로드 밸런서가 요청을 받으면,
연결 풀을 이용해 필요한 곳으로 전달한다.

#### Classic Load Balancer
Classic Load Balancer는 클래식 EC2 인스턴스를 지원하며, 네트워크 로드 밸런싱 및 애플리케이션 로드 밸런싱, 모두를 지원한다.

#### 3가지 차이점
> 328쪽 참조

#### X Forwarded-For 헤더란?
X-Forwarded-For (XFF) 헤더는 HTTP 프록시나 로드 밸런서를 통해 웹 서버에 접속하는 클라이언트의 원 IP 주소를 식별하는 사실상의 표준 헤더다.
클라이언트의 원 IP 주소를 보기위해 X-Forwarded-For 요청 헤더가 사용된다.

## 로드 밸런서의 용어

### 리스터
리스너는 트래픽이 유입되는 로드 밸런서 리스너의 연결 부분에 대한 프로콜과 포트를 정의한다.
유입 트래픽을 처리하기 위해 최소 하나 이상의 리스너가 필요하며 최대 열 개의 리스너를 지원한다.

### 타깃 그룹과 타깃
로드 밸런서에서 타깃 그룹은 타깃 그룹을 논리적으로 그룹화 한 것이다.
타깃은 EC2 인스턴스, 마이크로서비스, ALB의 컨테이너 기반 애플리케이션, IP 주소가 타깃으로 사용 될 수 있다.

### 규칙
로드 밸런서에서 규칙은 리스너와 타깃 그룹을 연결해주며, 조건과 동작으로 구성된다. 전달받은 요청이 규칙 조건에 부합하면 연관 동작이 일어난다.
예를 들어, 특정의 경로에서 이미지에 대한 요청을 만나면 이미지 호스팅 애플리케이션으로 라우팅하도록 할 수 있다. 이를 경로 기반 규칙이라고 한다.

### 헬스 체크
미리 정의된 주기별로 타깃과 타깃 그룹의 상태를 확인하는 동작이다. 예를 들어, 로드 밸런서에 네 개의 EC2 인스턴스가 연결돼 있고,
그중 하나의 인스턴스에서 CPU 사용량이 급증하면 헬스체크를 통해 문  상황이 발생했음을 알린다.
