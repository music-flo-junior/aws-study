# 6. Auto Scaling

# 6.1 Auto Scaling의 개요

Auto Scaling이란, 미리 정해 놓은 규칙에 따라 워크 로드를 자동으로 확대 또는 축소 할 수 있는 기술이다.

Auto Scaling을 이용하면 처리 요구량이 급등하는 시기, 즉 피크 워크로드에 맞춰 과잉 프로비저닝할 필요성이 사라진다.

# 6.2 Auto Scaling의 장점

- 동적 스케일링
    - 사용자의 요구 수준에 따라 리소스를 동적으로 스케일링할 수 있다.
- 최상의 사용자 경험 및 성능 향상
    - 항상 최적의 상태에서 실행되므로 어플리케이션 사용자에게 최상의 사용자 경험을 제공할 수 있다.
- 헬스 체크와 서버 플릿 관리
    - 서버 플릿: EC2 서버 집합
    - AutoSaling을 이용해 헬스 체크를 하는 과정에서 특정 인스턴스의 문제가 감지되면 자동으로 다른 인스턴스로 교체
    - ELB로 Auto Scaling 설정 시 ELB 헬스 체크 기능 사용 가능: 하드웨어 실패, 시스템 성능 약화 등 다양한 상태 확인 기능 사용
- 타깃 트래킹
    - 특정 타깃에 대해서만 Auto Scaling을 사용할 수 있으며, 사용자가 설정한 타깃에 맞춰 EC2 인스턴스 수를 조정한다.
- 리소스 비용 관리
    - 사용자 트래픽이 감소하는 늦은 저녁에는 Auto Scaling을 통해 필요량 이상의 리소스를 제거할 수 있다.
- 예측적 확장
    - 실제 EC2 사용량 정보를 수집한 뒤 머신러닝 모델을 이용해 일간 또는 주간 예상 트래픽에 따라 리소스 사용량을 예측 가능

EC2 외에도 EC2 스팟 인스턴스, ECS, EMR 클러스터, AppStream 2.0 인스턴스, Aurora Replicas, DynamoDB에도 적용 가능하다.

# 6.3 다양한 Auto Scaling 정책

## 6.3.1 리소스 확장 및 축소 계획 수립

AWS 리소스에 대한 확장 및 축소와 관련된 설정 및 관리 지침 마련

### 확장 가능한 리소스 파악

- CloudFormation 스택을 통한 검색
- 태그를 기준으로한 검색
- EC2 Auto Scaling 그룹

### 리소스 확장 전략 구체화

- 가용성 기준 최적화
    - 가용성 기준에 맞춰 자동으로 리소스의 스케일업 또는 스케일 다운 작업을 시행
    - CPU/리소스 활성화 기준 40%
- 가용성과 비용의 균형
    - 가용성과 비용의 균형에 초점
    - CPU/리소스 활성화 기준 50%
- 비용 기준 최적화
    - 비용을 낮추는 것에 초점
    - CPU/리소스 활성화 기준 70%
- 커스텀 스케일링 전략
    - 사용자는 자신이 원하는 CPU/리소스 활성화 수준 직접 입력

예측적 스케일링은 기업 어플리케이션에 대한 요구수준이 높아지기 전에 예방적으로 리소스를 프로비저닝 가능

## 6.3.2 EC2 AutoScaling 활용을 위한 각 단계

### 실행 환경 설정

- 확장 또는 축소하려면 먼저 어떤 서버를 사용할지 결정해야 하는데 이는 실행환경 설정에서 할 수 있다.
- 실행환경 설정은 일종의 템플릿으로, AMI 상세 정보, 인스턴스 타입, 키 페어, 시큐리티 그룹, IAM 인스턴스 프로파일, 유저 데이터, 부착 스토리지 등 인스턴스에 대한 모든 정보를 담고 있다.
- Auto Scaling 그룹을 생성한 뒤에는 이와 연결된 실행 환경 설정 파일을 수정할 수 없으므로 새로운 실행 환경 설정 템플릿을 만들어야 한다.

### Auto Scaling 그룹

Auto Scaling 그룹은 스케일업 및 스케일다운 규칙의 모음으로 EC2 인스턴스의 시작부터 삭제까지의 모든 동작에 대한 규칙과 정책을 담고 있다.

- 인스턴스 레벨 유지
    - 기본 스케일링 계획
    - 항상 실행 상태를 유지하고자 하는 인스턴스의 수를 정의한다
- 수동 스케일링
    - 콘솔이나 API, CLI 등을 이용해 수동으로 스케일링 작업을 수행할 수 있다.
- 요구별 스케일링
    - 시스템의 요구 수준에 맞추는 방식으로 CloudWatch가 모니터링하는 CPU, 디스크 쓰기와 읽기, 네트워크 유입과 유출 등 주요 지표를 바탕으로 요구 수준에 맞춰 스케일링 규칙을 정하는 방식이다.
- 일정별 스케일링
    - 트래픽의 변화를 예측할 수 있고, 특정 시간대에 어느 정도의 트래픽이 증가하는지 패턴을 파악하고 있다면, 일정별 스케일링을 사용하는 것이 좋다.

Amazon SNS(Simple Notification Service) 알림을 통해 Auto Scaling 그룹에게 스케일업 또는 스케일다운 시기를 알려 줄 수 있다.

하나의 Auto Caling 그룹에서는 동일한 인스턴스 타입을 사용하는 것이 좋다.

# 6.4 Auto Scaling 설정 방법

## 스케일링 정책

### 심플 스케일링

- 단 하나의 스케일링 정책에 따라 스케일업 및 스케일다운
- CPU 활용, 디스크 읽기 및 쓰기, 네트워크 유입 및 유출 비율 등을 지표로 인스턴스를 스케일 업 및 다운
- 새 인스턴스 시작 및 정지를 위한 대기시간(쿨 다운 시간: cooldown period) 설정 가능

### 단계별 심플 스케일링

- 심플 스케일링 정책에서 세분화해 CPU 활용률이 50~60%에 있을 때 2개의 인스턴스를 추가하고, 60%를 넘으면 4개의 인스턴스를 추가하는 등의 설정 방식

### 처리 용량

- 정확한 용량(Exact capacity)
    - 증가 또는 감소시킬 정확한 용량을 정의
    - ex) 현재 인스터 인스턴스가 2개고, 조정 용량이 4라면 4개로 인스턴스가 조정됨
- 숫자 지정 용량 변경(Change in capacity)
    - 숫자에 따라 현재 용량을 증가 또는 감소
    - ex) 현재 인스턴스가 2개고, 조정 용량이 4라면 6개로 인스턴스가 변경됨.
- 퍼센트 단위의 용량 변경
    - 퍼센트 단위로 현재의 용량을 증가 또는 감소
    - ex) 현재 인스턴스가 10개이고 20%가 조정 용량인 경우 12개의 인스턴스가 됨
    

### 타깃 트래킹 스케일링 정책

- 동적으로 환경을 설정
- 정의된 성능 지표를 이용하거나 커스텀 성능 지표를 만들어서 타깃 값으로 설정
- ex) CPU 50%로 지정하면, CPU 50%를 맞추기 위해 자동으로 계산해서 인스턴스 수를 증감함.

### 인스턴스 삭제 정책

- 스케일 다운 정책이 반영되면 EC2 인스턴스가 삭제
- 각 AZ에서 각각 하나씩의 인스턴스를 삭제해 균형을 맞추는 것이 좋다.
- 인스턴스 삭제를 위한 환경 설정 정책을 정의
- 인스턴스를 삭제하면 로드 밸런서에서 제외되고, 잠시 대기 상태에서 머물면서 다른 인스턴스 등과의 연결 상태를 끊게 되며, 최종적으로 삭제 작업이 완료
- 삭제 정책 종류
    - 서버 플릿에서 가장 오래된 서버 삭제
        - 가장 오래된 서버일수록 패치 수준이 낮고 메모리 누수 등의 문제가 누적해 있을 가능성이 크므로 이를 삭제
    - 시간 단위 과금이 임박한 서버를 삭제

# 6.5 Elastic Load Balancing의 개요

## Elastic Load Balancing

- 웹 서버 앞에 로드 밸런서를 배치해 트래픽을 분산시키고 워크 로드의 균형을 맞추며 탄력성을 증대
- ELB는 완전 관리형 서비스로 애플리케이션으로 유입되는 트래픽을 EC2 인스턴스에서 호스팅되고 있는 다수의 애플리케이션, 마이크로 서비스, 컨테이너 등에 자동으로 분산

### ELB의 장점

- 탄력성
    - 자동적 확장성
- 통합성
    - Auto Scaling으로 ELB를 통합하여 EC2 인스턴스 확장성 관리 및 워크로드 분산 업무를 더 효율적으로 수행할ㅜ있다.
- 안전성
    - ELB는 통합 인증 관리, SSL 복호화, 포트 포워딩 등 다수의 보안 기능을 제공한다.
- 고가용성
    - ELB는 다수의 EC2 인스턴스, 컨테이너, IP 주소 간에 트래픽을 분산시켜 고가용성 아키텍처를 구현하는데 도움을 준다.
- 저렴함
    - ELB는 저렴하며 비용 효율적이다.

# 6.6 Elastic Load Balancing의 작동 방식

내부적으로 각각의 ELB 인스턴스는 다중 AZ 환경에 구현되어 있다.

다중 AZ 환경에 개별 ELB VPC 내에 다수의 로드밸런서를 배포할 수 있다.

AWS에서 LB와 관련된 모든 업무를 자동으로 관리하며 별도 비용을 청구하지 않는다.

사용자는 ELB를 이용해 별도 고정비용 없이 고가용성을 구현할 수 있다.

# 6.7 다양한 로드 밸런싱 유형

## 6.7.1 Network Load Balancer(NLB)

- TCP 로드 밸런서
- OSI 레이어 4에서 작동
- 연결 기반 로드 밸런서로 EC2 인스턴스, 컨테이너, IP 주소 등의 연결을 관리
- 패킷 내용은 확인하지 않는다. NLB는 TCP와 SSL 모두 지원한다.
- 패킷 헤더를 수정하지 않으므로 패킷 내용을 바꾸거나 할 수 없다.
- X-Forwarded-For 헤더를 지니고 있지 않으므로 프록시 프로토콜이 소스 IP 주소 또는 데스티네이션 IP 주소, 요청 포트의 역할을 대신한다.

### 6.7.2 Application Load Balancer(ALB)

- OSI 레이어 7에서 작동
- HTTP와 HTTPS 지원
- 애플리케이션에서 패킷이 전달되면, 헤더로 받은 뒤 어디로 전송할지 결정한다
- LB가 요청을 받으면 연결 풀(Connection Pool)을 이용해 필요한 곳으로 전달
- X-Forwarded-For 헤더에 클라이언트 IP 주소를 넣듯 필요한 정보를 헤더에 삽입할 수 있다.
- 다수의 서버로 구성된 애플리케이션이 콘센트의 내용에 따라 특정 서비스로 라우팅할 수 있다.

### 6.7.3 Classic Load Balancer

- EC2 인스턴스를 지원하며, 네트워크 로드 밸런싱 및 애플리케이션 로드 밸런싱 모두를 지원한다.
- OSI 모델의 레이어 4, 7을 모두 지원한다.

- 내부 로드 밸런서
    - 기업용 프라이빗 서브넷에서 소수의 인스턴스를 위한 로드밸런서를 구현
- EC2-Classic 로드밸런서
    - 항상 인터넷을 향해 열려있음
- 외부형 로드밸런서
    - 퍼블릭 서브넷에 생성
- 내부형 로드밸런서
    - 프라이빗 서브넷에 생성
    

## 로드 밸런서의 핵심 개념과 용어

- 로드 밸런서는 고확장성, 고가용성의 완전 관리형 서비스다.

ex) orders와 images 도메인 어플리케이션이 있을 때 LB를 각각 붙인다면?

위 작업을 AWS LB를 이용해 처리한다면?

- Application Load Balancer로 처리 시
    - 경로 기반 라우팅으로 하나의 로드 밸런서만으로 주문 처리 및 이미지 처리 작업 수행 가능
    - 경로 기반 라우팅 이용 시 여러개의 애플리케이션을 호스팅할 수 있다.
- Class EC2
    - API를 이용해서 로드 밸런서로 인스턴스를 등록
    - 서로 다른 포트에 여러 번 인스턴스를 등록 가능
    - 컨테이너는 동적 포트를 지원하는 경우가 많으므로 애플리케이션 로드 밸런서로 어떤 포트든 등록 가능

ECS는 동적 포트 매핑 기법을 이용해 로드 밸런서의 포트 등록 업무를 자동으로 처리

EC2 인스턴스 대신 컨테이너를 사용한다면 높은 CPU 성능이 불필요하고 T2 마이크로 인스턴스를 사용해도 될 정도이므로 비용이 더욱 절감된다.

## 리스너

리스너는 트래픽이 유입되는 로드 밸런서 리스너의 연결 부분에 대한 프로토콜과 포트를 정의한다.

모든 라우팅 규칙은 리스너에 정의할 수 있따.

## 타깃 그룹과 타깃

로드 밸런서에서 타깃 그룹은 타깃 그룹을 논리적으로 그룹화한 것이다.