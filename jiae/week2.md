# 2. AWS 스토리지 서비스

## 1. AWS의 스토리지 서비스

- 객체 스토리지: S3
    - 문서, 이미지, 비디오 등 비교적 단순한 구조에 메타 데이터를 포함하고 있는 데이터 조각
    - API를 통해 데이터를 애플리케이션에 제공
- 블록 스토리지: EBS
    - 서버 인스턴스에 디스크 볼륨 형태로 제공되는 데이터
    - EBS는 EC2 인스턴스를 위한 부트 볼륨 및 데이터베이스로 널리 사용
- 파일 스토리지: EFS
    - 서버 인스턴스에 파일 시스템 인터페이스 또는 파일 시스템 시멘틱스 방식으로 제공되는 데이터

## 2. Amazon S3 사용 방법

### 2.1 Amazon Simple Storage Service(S3)

- 저장 용량 무제한, 고신뢰성
- S3 버킷에 단순한 네임스페이스만으로 저장

### 2.2 Amazon S3 주요 장점

- 간편성, 확장성, 신뢰성, 보안성, 고성능, 가용성, 저비용, 관리 용이성, 연계성

### 2.3 Amazon S3의 실무 활용 방법

- 데이터 백업
    - 기업용 데이터 백업 파일 저장 방식
    - S3 Standard, S3 Standard-Infrequent Access, S3 Glacier 스토리지 클래스 모두 리전 내 여러 개의 AZ로 분산되어 세 개의 복제물로 관리된다.
- 테이프 저장 장치
- 정적 웹 사이트 호스팅
- 애플리케이션 호스팅
- 재난 복구
- 콘텐츠 배포
- 데이터 레이크
    - 데이터 레이크는 기업에서 처리, 분석, 소비되는 막대한 양의 데이터를 보관하는 중앙 저장소이다.
    - 빅데이터 저장소
- 프라이빗 저장소

### 2.4 Amazon S3 기본 개념

- 버킷
    - 폴더 역할 수행
    - 버킷 이름은 유일무이한 이름으로 사용
    - 사용자는 버킷 URL을 통해 해당 데이터에 접근
    - 객체가 버킷에 추가될 때마다 해당 객체에 유일한 ID 할당
    - 버킷 내에서 객체는 이름, 키, 또는 버전 ID를 통해 식별 가능
- API
    - S3는 API를 통해 접근할 수 있으며, 개발자는 S3 기반의 어플리케이션을 개발할 수 있다. S3의 기본 인터페이스는 REST API이다.

```jsx
$ aws s3 mb s3://bucket-name // 버킷 생성
$ aws s3 rb s3://bucket-name // 버킷 삭제
```

### 2.5 Amazon S3 데이터 일관성 모델

S3 인프라는 기본적으로 복수의 AZ 위에 다수의 로드 밸런서, 웹 서버, 스토리지로 구성된다.

저장이 되면 인덱싱 작업이 진행되고, 다수의 AZ와 스토리지에 중복 저장된다.

- 판독 일관성
    - 새 객체를 작성하면 데이터는 동기적으로 다수의 클라우드 설비에 저장
- 종국적 일관성
    - 데이터가 자동으로 복제돼 동일 리전 내 다수의 시스템 및 다수의 AZ에 확산
    - 최신 내용으로 변경한 내용이 즉각적으로 반영되지 않거나 업데이트 직후 데이터를 읽으려 할 때 변경된 내용을 확인할 수 없게 될 가능성이 있다.
- 아토믹 특성
    - 기존 KEY를 PUT할 경우 최종 읽기 실행 결과는 업데이트 전 데이터 또는 업데이트 후 데이터만 나타날 수 있으며 일부만 수정될 가능성은 없다.
- 객체 잠금 기능을 지원하지 않는다
    - 동시에 PUT 요청이 들어오는 경우 최종 타임 스탬프를 지닌 요청을 따른다.

### 2.6 Amazon S3 성능 고려

S3 버킷에 초당 100회 이상의 put, list, delete 요청을 하거나 300회 이상의 get 요청을 해야 하면 워크로드를 적절히 파티셔닝, 즉 분산해야 한다.

- 키 프리픽스 파티셔닝
    - 객체의 시작 단어를 기준으로 파티셔닝한다.
    - ex) `2chapter/image/image2_1.jpg`
- 키 이름을 역순 배열
    - ID가 1씩 추가되는 경우
    - ex) `applicationid/23112333125/log.text`
          `applicationid/33112333125/log.text`
- 키 이름에 hex hash 프리픽스를 추가하는 방법
    - 16 진수 계열의 Hex Hash를 프리픽스로 추가해 적절한 무작위성을 반영
    - 알고리즘 특유의 랜덤 속성에 주의한다. (파티션 키가 너무 많이 생성될 수 있음)

### 2.7 Amazon S3 암호화

- 전송 중인 데이터를 암호화
- 저장된 데이터를 암호화
    - Amazon S3 키 매니지먼트 기반의 SSE(SSE-SE)
        - Amazon S3가 저장된 데이터를 암호화하고, 암호화 키 또한 관리하는 방식
    - 고객 자체 생성 키 기반의 SSE(SSE-C)
        - 고객이 자체 생성한 커스텀 암호화 키로 데이터를 암호화하는 방식
    - AWS KMS 기반의 SSE(SSE-KMS)
        - KMS를 이용해서 암호화하는 방식

### 2.8 Amazon S3의 접근성 통제

### 2.9 접근 정책

### 2.9.1 IAM 정책

IAM 정책을 정의하여 특정 유저가 해당 버킷에 접근하도록 허용. ARN(Amazon Resource Name)을 알아야 한다.

`arm:partition:service:region:account-id:resource`

예) `arm:aws:s3:::bucket_name`

```jsx
"Version":"2017-06-07",
"Statement":[
  {
    "Effect":"Allow",
		"Action":[
			"s3:PutObject",
			"s3:GetObject"
		],
	"Resource":"arn:aws:s3:::my_bucket_forawsbook/${aws:username}/*"
  }
]}
```

### 2.9.2 버킷 정책

특정 버킷에 있는 객체에 대한 익명의 사용자로부터의 리드 온리 접근을 허용한다. 정적 웹사이트를 운영하거나 웹을 통해 불특정 다수의 접근을 허용할 때 자주 사용되는 방법이다.

```jsx
"Version":"2017-06-07",
"Statement":[
  {
    "Effect":"Allow",
		"Principal": "*",
		"Action":[
			"s3:GetObject"
		],
	"Resource":["arn:aws:s3:::mybucket/*"]
  }
]}
```

### 2.9.3 접근 제어 목록(ACL)

- ACL을 통해 S3의 버킷 레벨 또는 객체 레벨에서 접근을 제어할 수 있다.
- ACL을 통해 기업 계정에 포함된 직원들 이외에 사용자에게는 기본적인 리드 온리 권한만 부여할 수 있다

### 보안의 베스트 프랙티스

- S3 버킷에 대한 퍼블릭 액세스를 허용해서는 안 된다.
- 최소한의 ‘접근 권한’ 전략 사용
- 다중인증(MFA) 시스템 활용
    - MFA Delete 설정은 데이터의 삭제 권한이 없는 사람은 삭제 작업을 할 수 없도록 제한한다.
- S3 버킷에 대한 감사를 수행한다.
- IAM 롤을 활용한다.

### 2.10 Amazon S3 스토리지 클래스

- Amazon S3 Standard
    - 기본형 스토리지로 빈번하게 접근하는 데이터용
    - 고신뢰성, 고가용성, 고성능
- Amazon S3 Standard IA(Infrequent Access)
    - 상대적으로 접근 빈도가 낮은 데이터를 위한 스토리지 클래스
- Amazon S3 One Zone-IA
    - 평소에는 낮은 빈도로 접근하지만, 때에 따라서 매우 신속하게 접근할 수 있는 스토리지 클래스
    - 단일 AZ에만 저장
- Amazon S3 Intelligent Tiering
    - 엑세스 패턴에 따라 자동으로 하나의 스토리지에서 다른 스토리지로 이동시켜 비용을 최적화한다.
    - 데이터를 자동으로 옮길 수 있다.
- Amazon S3 Glacier
    - 데이터 아카이브, 데이터 장기보관을 목적으로 활용
- Amazon S3 Glacier Deep Archive
    - 데이터를 연간 한 번 또는 두 번 정도 이용
    - 보관된 데이터를 복원하는 데는 최대 12시간 소요

### 2.11 Amazon S3에서의 객체 버전 관리

- 버저닝은 동일한 파일의 다양한 업데이트 상태를 관리하는 방법
- 복원이 가능하도록 버저닝 기능을 지원
- GET 요청은 최신 버전의 파일을 가져온다.
- 버저닝과 라이프사이클을 같이 이용하면 30일이 경과한 이전 버전 파일은 S3 Glacier로 이동시키고, 30일 지나면 S3 Glacier에서 삭제하도록 설정 가능

### 2.12 Amazon S3 객체 라이프 사이클 관리

- 파일 이동
    - 서로 다른 클래스 간에 객체를 이동시키는 규칙
- 파일 소멸
    - 객체가 소멸된 후의 사항 정의 (임시보관 등)

### 2.13 Amazon S3 복제

- 교차 리전 복제(CRR, Cross-Region Replication)
    - 서로 다른 리전 간의 객체 복제에 사용
- 동일 리전 복제(SRR, Single-Region Replication)
    - 동일 리전 내에서의 객체 복제에 사용

### CRR 적용 시 고려사항

- 소스와 타깃 버킷에 버저닝 기능 활성화 필수
- 소스 버킷 오너는 복제에 사용할 타깃 리전 지정 (SRR일 경우 해당 규칙 적용 안함)
- S3 파일 복제 퍼미션 룰 필요, 복제할 객체의 READ 및 READ_ACP 퍼미션 부여 필요

### 2.14 Amazon S3에서 정적 웹사이트 호스팅 하기
완료오

## 3. Amazon Glacier 사용 방법

Amazon S3 Glacier는 데이터 아카이브 및 장기 보관 백업을 위한 저비용 클라우드 스토리지다. 월간 1테라바이트당 1달러로 매우 저렴하다.

### 3.1 Glacier 활용처

- 자기 테이프 스토리지 대체
- 헬스케어, 생명과학, 과학 데이터 저장
- 미디어 자산 아카이빙/디지털 보관
- 규제 정책에 따른 아카이빙/장기 백업 보관

### 3.2 Amazon S3 Glacier 주요 용어

- 데이터 아카이브에 저장 시 tar, zip 압축 후 업로드 권장
- 아카이브의 용량은 최소 1byte에서 최대 40TB
- 아카이브는 금고 역할을 수행하는 볼트에 저장됨.
- 볼트 잠금정책에 WORM(Write Once Read Many) 규칙을 추가해 다른 사용자의 편집, 수정을 막을 수 있음

### 3.3 Amazon S3 Glacier에 파일 업로드하기

1. 데이터 업로드 시 볼트 먼저 생성
2. 볼트에 접근할 수 있는 권한 설정
3. 아카이브 생성 및 볼트 업로드

### 3.4 Amazon S3 Glacier에서 파일 가져오기

- 스탠다드: 몇 시간이 소요되는 저비용 데이터 인출 방식. 인출에 3~5시간 소요. 기가 바이트당 $0.01 비용 부과
- 엑스퍼다이티드: 소수의 아카이브에 대한 일시적이고 긴급한 인출 방식. 인출에 1~5분 소요. 기가바이트당 $0.03 비용 부과
- 벌크: 페타바이트급 데이터를 위한 최저 비용 인출 방식. 인출에 5~12 시간 소요. 기가바이트당 $0.0025의 비용 부과

### 3.5 Glacier 인출 작업 4단계

1. 데이터 인출을 위한 리트리벌 잡 제출  (인출 타입 설정). 제출 완료 시 모니터링 잡 ID 발급
2. 리트리벌 잡은 수 분에서 수 시간 소요
3. 완료 알림 메시지
4. 인출할 데이터 다운로드

## 4. Amazon Elastic Store 사용 방법

EC2 인스턴스를 위한 영구 스토리지 기능 수행

하나의 EC2 인스턴스에 여러 개의 EBS 볼륨을 부착할 수 있는데 이렇게 하면 부 볼륨과 데이터 볼륨을 별도로 관리할 수 있음

### 4.1 EBS 특징

- 영구 스토리지: EC2 인스턴스와 독립적인 생애주기
- 범용성: 어떤 OS에서도 사용 가능
- 고가용성 및 고신뢰성: 동일 AZ 내에서 자동 복제. EBS 볼륨은 서로 다른 AZ 간에 복제되지 않음. 동일 AZ 내 다른 서버 간 복제 가능
- 암호화 지원: EC2 인스턴스와 EBS 볼륨 간을 이동할 때, 저장할 때 암호화 지원
- 다양한 저장 용량: 1GB 에서 16TB 까지 다양한 볼륨 지원
- 사용 편의성: 쉽게 생성, 부착, 백업, 복원, 삭제 가능
- 실패 대응성: 연간 실패율(AFR) 0.1~0.2 퍼센트에 불과

### 4.2 EBS의 주요 서비스

- Amazon EC2 인스턴스 스토어
    - EC2 인스턴스 로컬 스토리지. EC2 인스턴스를 셧다운하면 여기에 저장된 내용도 사라진다.
- Amazon EBS Elastic 볼륨
    - 동적인 용량 증대, 성능 튜닝, 성능 저하 없이 기존의 볼륨 변경 가능
- Amazon EBS SSD-기반 볼륨
    - 미리초 단위의 전송 지연 허용. 대부분의 워크로드에 적합
- 프로비전 IOPS SSD
    - 기업용 데이터베이스와 같이 IO 성능이 중요한 워크로드에 적합
- Amazon EBS HDD-기반 볼륨
    - 처리 성능 최적화 HDD(st1)
        - 볼륨은 크게, 높은 빈도의 입출력 및 처리 성능
    - 콜드 HDD
        - 낮은 빈도의 입출력 및 저렴한 비용

## 5. Amazon Elastic File System 사용 방법

EC2 인스턴스를 위한 파일 시스템 인터페이스 및 파일 시스템 시멘틱 환경 제공

### 5.1 EFS 주요 속성

- 완전 관리형
- 파일 시스템 엑세스 시멘틱
- 파일 시스템 인터페이스
- 공유 파일 시스템
- 민첩성 및 확장성
- 고성능
- 고가용성 및 고신뢰성
- 간편성
- 탄력성: 파일 시스템 크기 자동 확대 및 축소

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7ac38971-afb8-4b6c-9d90-cdcff1da4e6c/Untitled.png)

다수의 AZ에 자동으로 복제됨.

### 5.2 EFS 사용 절차

1. 파일 시스템 생성
2. 각 AZ에서 파일 시스템을 통해 접근하려는 마운트 타깃 생성
3. EC2 인스턴스에서 EFS 마운트의 DNS 이름으로 마운트 명령 실행
4. EFS 사용

## 6. 대량의 데이터를 AWS로 옮기는 방법

데이터센터에서 클라우드로 대량의 데이터 (10TB 이상)의 데이터 전송 시 AWS와 온프레미스 스토리지 통합 방안 고려

### 6.1 AWS Storage Gateway

VM 게이트웨이를 AWS에 연결해 데이터를 Glacier에 저장 가능

Storage Gateway에서 제공하는 세 가지 스토리지 인터페이스

- 파일 게이트웨이
- 볼륨 게이트웨이
- 테이프 게이트웨이

### 6.2 AWS Snowball과 AWS

Snowball은 Amazon의 스토리지 디바이스를 이용한 페타바이트 규모의 데이터 이전을 위한 임포트/익스포트 도구이다.

### 6.3 AWS Snowmobile

엑사바이트 규모의 데이터 이전 서비스 (최대 100PB)

## 2장 평가 오답 풀이

Q2. Amazon S3에서 의도치 않은 삭제를 방지하기 위한 가장 좋은 방법은?

- S3 버킷에서 버저닝 기능 활성화

Q3. amazon S3는 99.999999...% 신뢰도를 자랑합니다에 대한 설명으로 옳은 것

- 데이터는 리전 내에서 다수의 AZ에 복제된다.
- Amazon S3 스탠다드는 두 개의 시설 의 동시 재해 상황을 가정해 설계된다

Q4. 크로스 리전 복제를 설정하기 위한 내용으로 옳은 것은?

- 소스 버킷과 타깃 버킷은 다른 리전이어야 한다.
- 복제를 위해 버저닝을 활성화해야 하고 IAM 정책을 설정해야 한다.

Q15. 중요성이 높지 않은 빅데이터 분석 작업을 위해 멜리듀스 잡을 실행하려 한다. 이번 작업의 목표는 비용 대비 효율성 최대화이며, 처리 성능에는 민감하지만 작업의 우선순위 및 신속성은 높지 않고 상당한 시간이 소요될 수 있다. 이에 적합한 스토리지 타입은?

- 콜드 HDD(sc1)