# AWS 공인 솔루션스 아키텍트 올인원 어소시에이트

## 6장. Auto Scaling

Auto Scaling 은 미리 정해 놓은 규칙에 따라 워크로드를 자동으로 확대 또는 축소할 수 있는 기술로 클라우드가 제공하는 탄력성에 의해 만들어지고, 사용자의 요구 사항을 세심하게 반영할 수 있는 혁신적인 기술이다.

Auto Scaling 을 이용하면 처리 요구량이 급등하는 시기, 즉 피크 워크로드에 맞춰 과잉 프로비전을 할 필요성이 사라진다.


Auto Scaling은 새 리소스를 자동으로 추가하고 환경 설정하며, 처리 요구량이 줄어들면 해당 리소스를 감소시킨다.

AWS의 Auto Scaling과 Elastic Load Balancing을 이용하면 다수의 EC2 서버의 처리 능력을 적절히 분배해 워크로드 상승에 맞춰 서버의 처리 성능을 높이고, 워크로드 하락에 맞춰 서버의 처리 성능을 감소시킬 수 있다.

사용자는 몇 가지 파라미터가 포함된 규칙을 작성해 워크로드 처리에 적합한 수준의 리소스만을 투입할 수 있다.

(AutoScaling은 AWS의 다양한 제품군에서 사용할 수 있으며, EC2로만 한정해 생각하지 않기를 바란다.)

### Auto Scaling 의 장점

Auto Scaling 의 장점은 다음과 같다.

1. 동적 스케일링 

Auto Scaling 의 가장 큰 장점으로 사용자의 요구 수준에 따라 리소스를 동적으로 스켈링할 수 있다.

스케일업할 수 있는 서버의 수에는 제한이 없고, 필요한 경우 서버 두 대에서 수백 대, 수천 대, 수만 대의 서버로 즉시 스케일업할 수 있다.

Auto Scaling을 통해 기업의 애플리케이션에 항상 최적의 CPU 및 메모리 등의 리소스를 제공할 수 있으며, 사용자는 이를 실시간으로 프로비전할 수 있다.

2. 최상의 사용자 경험 및 성능 향상

Auto Scaling 을 이용하면 리소스가 항상 적정 수준에서 제공되고 애플리케이션은 항상 최적의 상태에서 실행되므로 애플리케이션 사용자에게 최상의 사용자 경험을 제공할 수 있다.

새 인스턴스가 시작될 때 CPU 활용률을 70% 로 설정하는 것과 같이 다양한 Auto Scaling 규칙을 추가해 애플리케이션 사용자에게 최상의 사용자 경험을 제공할 수 있다.

3. 헬스 체크와 서버 플릿 관리

Auto Scaling 을 이용하면 EC2 인스턴스의 헬스 체크 상태를 모니터링 할 수 있다.

다수의 EC2 서버에서 애플리케이션을 호스팅하는 경우 이들 일련의 EC2 서버 집합을 AWS는 서버 플릿이라 부른다.

Auto Scaling 를 이용해 헬스 체크를 하는 과정에서 특정 인스턴스의 문제가 감지되면, 자동으로 다른 인스턴스로 교체한다.

또한 적정 수준의 서버 플릿 용량을 유지하는 데도 도움을 준다.

ELB으로 Auto Scaling 을 설정하는 경우, ELB의 헬스 체크 기능도 사용할 수 있다.

4. 로드 밸런싱

ELB와 함께 사용하면 다수의 EC2 인스턴스에게 워크로드를 효과적으로 분배할 수 있고, 다수의 AZ에 분포된 EC2 인스턴스에 대한 워크로드도 자동으로 분배하도록 설정할 수 있다.

5. 타깃 트래킹

사용자는 특정 타깃에 대해서만 Auto Scaling을 할 수 있으며, 사용자가 설정한 타깃에 맞춰 EC2 인스턴스의 수를 조정한다.

타깃이 Auto Scaling 을 하기 위한 지표로 활용될 수 있는 것이다.

예를 들어, Auto Scaling 타깃으로 애플리케이션 서버의 CPU 활용률을 65%로 설정하면, Auto Scaling 은 CPU 활용률 65%에 맞춰 EC2 인스턴스의 수를 자동으로 조정한다.

6. 리소스 비용 관리

Auto Scaling 을 이용하면 불 필요한 리소스를 자동으로 제거해 예산 낭비를 막을 수 있다.

7. 예측적 확장

Auto Scaling 은 머신러닝과 통합됐으며, ML Auto Scaling 을 이용해서 수요 예측치에 근거해서 컴퓨트 용량을 자동으로 확장 또는 축소할 수 있다.


Auto Scaling 은 EC2에서 가장 많이 사용되지만 EC2 이외의 다른 서비스의 스케일 조정에도 활용된다.

사용자는 Auto Scaling 의 스케일 정책 정의를 통해 아래와 같은 서비스의 스케일 업 또는 다운 업무를 자동으로 수행할 수 있다.

- EC2 스팟 인스턴스
- EC2 Container Service
- Elastic Map Reducer 클러스터
- AppStream 2.0 인스턴스
- Amazon Aurora Replicas
- DynamoDB

### Auto Scaling 실제 작동 방식

Auto Scaling 을 이용하면 Auto Scaling 그룹에 EC2 인스턴스를 추가하고, 서버의 최소 대수 및 최대 대수를 정의한 후 스케일링 정책을 정의하면 된다.

Auto Scaling은 사용량에 따라 서버 추가, 삭제, ELB 와의 통합을 관리한다.

( 그럼, Auto Scaling 에 설정된 최대 대수 이상의 서버는 증설될 수 없는건가? )

### 리소스 확장 및 축소 계획 수립

Auto Scaling 활용의 첫 번째 단계는 리소스 확장 및 축소 계획을 수립하는 것이다.

스케일링 계획은 Auto Scaling 을 지원하는 모든 리소스에 적용할 수 있다.

다음은 스케일링 계획을 수립하기 위한 주요 절차다.

1. 확장 가능한 리소스 파악

Auto Scaling 계획을 적용하려는 리소스는 자동 또는 수동으로 탐색 및 선택할 수 있으며, 다음과 같이 세 가지 방법이 있다.

> CloudFormation 스택을 통한 검색

기존의 AWS CloudFormation 스택을 이용해 자동화된 스케일링 환경 설정이 가능한 리소스를 찾아낼 수 있다.

Auto Scaling 은 선택된 스택 내에 정의된 리소스만 찾을 수 있으며, 여러 단계로 중첩된 스택 속을 순회하며 탐색할 수는 없다.

이때 스택은 이미 성공적으로 생성된 것이어야 하고, 작업이 진행 중인 스택은 탐색할 수 없다.

> 태그를 기준으로 한 검색 

다음 리소스를 찾을 때는 태그도 이용할 수 있다.

- Aurora DB 클러스터
- Auto Scaling 그룹
- DynamoDB 테이블과 전역 보조 인덱스

이때 하나 이상의 태그를 이용해서 검색하면 해당 태그를 모두 포함하고 있는 리소스만 검색 결과로 나타난다.

> EC2 Auto Scaling 그룹

스케일링 계획에 하나 이상의 Auto Scaling 그룹을 선택해서 추가할 수 있다.

### 리소스 확장 전략 구체화

Auto Scaling 을 적용할 리소스를 파악했다면 해당 리소스의 스케일업 또는 다운 전략을 설정한다.

리소스 스케일링 전략은 다음과 같은 네 가지가 있다.

1. 가용성 기준 최적화

이 옵션을 선택하면 Auto Scaling 은 가용성 기준에 맞춰 자동으로 리소스의 스케일업 또는 스케일다운 작업을 시행한다.

이 옵션에서 Auto Scaling 은 CPU / 리소스 활성화 수준을 40 퍼센트로 맞춘다.

2. 가용성과 비용의 균형

이 옵션을 선택하면 가용성과 비용의 균형에 초점을 맞춰서 리소스의 확장 여부를 결정한다.

이 옵션에서 Auto Scaling 은 CPU/리소스 활성화 수준을 50퍼센트로 설정해 가용성과 비용의 균형을 맞춘다.

3. 비용 기준 최적화

이 옵션의 목적은 비용을 낮추는 것이다.

이 옵션에서 Auto Scaling 은 CPU/리소스 활성화 수준을 70 퍼센트로 설정하며, 이는 성능의 중요성이 높지 않은 로우레벨 환경에 적합하다.

4. 커스텀 스케일링 전략

이 옵션을 선택하면 Auto Scaling 은 원하는 지표에 따라 리소스의 확장 여부를 결정할 수 있으며, 사용자는 자신이 원하는 CPU/리소스 활성화 수준을 직접 입력할 수 있다.

스케일링 전략 선택 시 예측적 스케일링 및 동적 스케일링도 사용할 수 있다.

1. 예측적 스케일링

예측적 스케일링 정책을 활성화하면 머신러닝이 과거의 워크로드 처리 유형을 분석하고 미래의 워크로드 유형을 예측하게 된다.

예측적 스케일링은 기업 애플리케이션에 대한 요구 수준이 높아지기 전에 예방적으로 리소스를 프로비전할 수 있다는 장점이 있다.

2. 동적 스케일링 

스케일링 계획에 포함된 리소스에 대한 목표 추적 스케일링 정책을 생성해 리소스 확장을 관리하게 된다.

EC2 서버를 CPU 성능의 60퍼센트로 제한해 사용할 수 있다. 이후 CPU 활성화 수준이 60 퍼센트를 초과하면 리소스 확장과 관련된 스케일링 정책이 실행되게 할 수 있다.

즉, 동적 스케일링은 리소스 활성화 수준에 실시간으로 반응해 리소스의 확장 여부를 결정할 수 있다는 장점이 있다.

### EC2 Auto Scaling 활용

EC2 Auto Scaling 활용을 위한 각 단계를 알아보자.

1. 실행 환경 설정

Auto Scaling 으로 인스턴스를 확장 또는 축소하려면 먼저 어떤 서버를 사용할지 결정해야 하는데 이는 실행 환경 설정에서 할 수 있다.

실행 환경 설정은 일종의 템플릿으로 AMI 상세정보, 인스턴스 타입, 키 페어, 시큐리티 그룹, IAM 인스턴스 프로파일, 유저 데이터, 부착 스토리지 등, 인스턴스에 대한 모든 정보를 담고 있다.

실행 환경 설정 템플릿을 생성한 뒤 이를 Auto Scaling 그룹에 연결할 수 있으며, 한 번 작성한 실행 환경 설정 템플릿은 다른 Auto Scaling 그룹에 적용할 수 있다.

단, Auto Scaling 그룹은 항상 하나의 실행 환경 설정 템플릿만 지닐 수 있다.

Auto Scaling 그룹을 생성한 뒤에는 이와 연결된 실행 환경 설정을 수정할 수 없으며, 수정 또는 변경이 필요한 경우 새로운 실행 환경 설정 템플릿을 추가한 뒤 연결 해야 한다.

그리고 인스턴스를 다시 실행하면 새 Auto Scaling 그룹의 내용이 적용된다.

2. Auto Scaling 그룹

Auto Scaling 그룹은 스케일업 및 스케일다운 규칙의 모음으로 EC2 인스턴스의 시작부터 삭제까지의 모든 동작에 대한 규칙과 정책을 담고 있다.

Auto Scaling 그룹은 EC2 서버가 하나의 그룹으로 작동하는 방법과 사용자 정의에 따라 동적으로 그룹화하는 방법을 정의한다.

Auto Scaling 그룹을 정의하려면 인스턴스 타입 등 세부 정보를 담은 실행 환경 설정을 생성한 뒤 스케일링 계획 및 스케일링 정책을 선택한다.

스케일링 유형 다음과 같다.

- 인스턴스 레벨 유지

기본 스케일링 계획으로도 부르며, 항상 실행 상태를 유지하고자 하는 인스턴스의 수를 정의할 수 있다.

예를 들어, 사용자가 항상 6대의 인스턴스를 실행하길 원한다면 하드웨어 실패 또는 여타의 이슈에 의해 인스턴스가 다운돼도 Auto Scaling 그룹이 문제가 생긴 인스턴스 수만큼을 추가로 실행해 언제나 6대의 서버를 유지한다.

- 수동 스케일링

콘솔이나 API, CLI 등을 이용해 수동으로 스케일링 작업을 수행할 수 있다. 수동 스케일링을 선택하면 사용자가 직접 인스턴스 추가 또는 삭제 해야 한다.

스케일 자동화라는 Auto Scaling 의 기본 취지를 생각하면 수동 스케일링 방식은 추천하지 않는다.

- 요구별 스케일링

시스템의 요구 수준에 맞추는 방식으로 CloudWatch 가 모니터링하는 CPU, 디스크 쓰기와 읽기, 네트워크 유입과 유출 등 주요 지표를 바탕으로 요구 수준에 맞춰 스케일링 규칙을 정하는 방식이다.

예를 들어, CPU 처리 용량의 80% 수준까지 급등한 상태가 5분 이상 지속될 경우 Auto Scaling 이 작동돼 새 서버를 추가하는 방식이다.

이와 같은 스케일링 정책을 정의할 때는 항상 두 개의 정책을 작성해야 하며, 하나는 스케일업, 다른 하나는 스케일 다운 정책을 담는다.

- 일정별 스케일링

트래픽의 변화를 예측할 수 있고, 특정 시간대에 어느 정도의 트래픽이 증가하는지 패턴을 파악하고 있다면, 일정별 스케일링을 사용하는 것이 좋다.

Auto Scaling 그룹을 생성할 때는 항상 실행해야 하는 최소한의 인스턴스 수를 정의해야 하며, 스케일업 상황에서 추가할 최대 인스턴스 수 또한 정의해아 한다.

경우에 따라 아래와 같이 이상적인 처리 성능을 확보하기 위해 시스템이 실행시켜애 할 최적의 인스턴스 수를 정의할 수 있다.

- 이상적인 처리 성능이 현재의 처리 성능보다 높은 경우, 인스턴스를 추가해 실행한다.
- 이상적인 처리 성능이 현재의 처리 성능보다 낮은 경우, 추가된 인스턴스를 삭제한다.

> Amazon SNS

언제 Auto Scaling 그룹이 애플리케이션을 위해 서버 수를 증가시키거나 감소시키는 지를 파악하는 것은 중요한 일이다.

이를 위해 Amazon SNS를 이용할 수 있고, SNS 알림을 통해 Auto Scaling 그룹에게 스케일업 또는 다운 시기를 알려줄 수 있다.

아마존 SNS는 HTTP, HTTPS, POST, 이메일은 물론 아마존 SQS의 메시지 큐 방식으로 알림을 보낼 수 있다.

> 스케일링 정책 유형

스케일링 정책은 다음과 같이 세가지 유형이 있다.

1. 심플 스케일링

단 하나의 스케일링 정책에 따라 스케일 업 및 다운 할 수 있다. 이 정책 유형에서 사용자는 CPU 활용, 디스크 읽기 및 쓰기, 네트워크 유입 및 유출 비율 등을 경고 지표로 삼아 인스턴스를 스케일 업 및 다운 할 수 있다.

예를 들어, CPU 활용 지표가 80% 에 도달할 때 하나의 인스턴스를 추가하고, 40% 미만으로 떨어지면 하나의 인스턴스를 감소시키는 방식이다.

이때 새 인스턴스의 시작 또는 정지를 위한 대기 시간도 정의할 수 있으며, 이를 쿨다운 기간이라 부른다.

2. 단계별 심플 스케일링

심플 스케일링은 이벤트에 반응해 스케일링하며 특정 이벤트에 대해 매번 같은 액션을 수행한다.

하지만 때로는 좀 더 세분화된 이벤트 대응 액션이 필요하다.

CPU 활용률이 50~60%에 있을 때 2개의 인스턴스를 추가하고, 60% 넘으면 4대의 인스턴스를 추가하도록 할 수 있다.

이와 같은 스케일링 환경 설정 방식이 바로 단계별 심플 스케일링 이다.

전반적인 내용은 심플 스케일링과 동일하지만 환경 설정 마지막 부분에서 몇 단계를 추가한다.


> 처리 용량 변경

심플 스케일링 또는 단계별 심플 스케일링을 이용하면 다음과 같이 처리 용량을 변경할 수 있다.

1. 정확한 용량

스케일 정책 작성 시 증가 또는 감소시킬 정확한 용량을 정의할 수 있다.

그룹의 현재 용량이 2개의 인스턴스고 조정 용량이 4개의 인스턴스인 경우 Auto Scaling 정책이 실행되면 4개의 인스턴스로 변경된다.

2. 숫자 지정 용량 변경

숫자에 따라 현재의 용량을 증가 또는 감소 시킬 수 있다.

현재 용량이 2개의 인스턴스고 조정 용량이 4개인 경우, Auto Scaling 정책이 실행되면 6개의 인스턴스로 변경된다.

3. 퍼센트 단위의 용량 변경

퍼센트 단위로 현재의 용량을 증가 또는 감소시킬 수 있다.

- 타깃 트래킹 스케일링 정책

동적으로 환경을 설정할 수 있는 타깃 트래킹 스케일링 정책이다.

미리 정의된 성능 지표를 이용하거나 커스텀 성능 지표를 만들어서 타깃 값으로 설정할 수 있다.

### 인스턴스 삭제 정책

Auto Scaling 은 스케일 업 정책은 물론, 스케일다운 정책도 반영한다.

스케일다운 정책이 반영되면 EC2 인스턴스가 삭제되며, 서버를 셧다운하는 것은 좀 더 확실한 리소스 관리를 위해서도 필요한 일이다.

스케일다운 정책에서 정확하게 몇 개의 인스턴스를 삭제할 것인지 정의할 수 있다.

### Elastic Load Balancing

AWS ELB 는 온프레미스 환경 > 로드 밸런서 문제를 모두 해결할 수 있는 완전 관리형 서비스로 애플리케이션으로 유입되는 트래픽을 EC2 인스턴스에서 호스팅되고 있는 다수의 애플리케이션, 마이크로서비스, 컨테이너 등에 자동으로 분산 시킨다.

AWS ELB의 주요 장점은 아래와 같다.

1. 탄력성 

ELB의 최대 장점은 자동적 확장성이다.

2. 통합성

ELB는 다양한 AWS 서비스와 통합해 사용할 수 있다.

AutoScaling 으로 ELB를 통합하면 EC2 인스턴스 확장성 관리 및 워크로드 분산 업무를 더 효율적으로 수행할 수 있다.

Route S3 와 ELB를 통합해 DNS 실패에 대비할 수 있다.

3. 안전성

ELB는 통합 인증 관리, SSL 복호화, 포트 포워딩 등 다수의 보안 기능을 제공한다.

4. 고가용성 

ELB는 최고 수준의 고가용성 아키텍처를 구현하는 데 도움을 준다.

ELB는 다수의 EC2 인스턴스, 컨테이너, IP 주소 간에 트래픽을 분산 시키며, 다수의 AZ에 배포된 EC2 인스턴스에 애플리케이션을 배포해 트래픽을 여러 AZ로 분산시킬 수 있다.

5. 저렴함

ELB 는 저렴하여 비용 효율적이다.

로드 밸런싱 작업을 자동화해 많은 비용을 줄여주며 네트워크 관리자의 시간과 노력 또한 크게 줄여준다.

### 로드 밸런서 유형 (ELB 유형)

AWS에서 제공하는 로드 밸런서는 다음과 같이 크게 세 가지 타입이 있다.

1. Network Load Balancer

TCP 로드 밸런서라고도 부르며, OSI 모델의 레이어 4에서 작동한다.

NLB는 기본적으로 연결 기반 로드 밸런서로 EC2 인스턴스, 컨테이너, IP 주소 등의 연결을 관리한다.

이들이 생성하는 모든 요청은 로드 밸런서를 통해 흘러가며, 로드 밸런서는 전달되는 패킷을 관리하고, 이를 백엔드로 전달하는 역할을 수행한다.

2. Application Load Balancer

ALB는 OSI 모델의 레이어 7에 해당하며, HTTP 와 HTTPS를 지원한다.

애플리케이션으로부터 패키지가 전달되면, 헤더로 받은 뒤 어디로 전송할지 결정한다.

이 연결은 로드 밸런서에서 종료되고 전달 내용은 연결 풀형태로 모여있다가 로드 밸런서가 요청을 받으면, 연결 풀을 이용해 필요한 곳으로 전달한다.

3. Classic Load Balancer

클리식 EC2 인스턴스를 지원하며, 네트워크 로드 밸런싱 및 애플리케이션 로드밸런싱 모두를 지원한다.

클래식 EC2 인스턴스를 사용하는 경우가 아니라면 필요에 따라 네트워크 로드 밸런싱 또는 애플리케이션 로드 밸런싱을 사용해야 한다.

> 외부형 / 내부형 로드밸런서

로드 밸런서는 외부형 또는 내부형으로 설정할 수 있으며, 인터넷을 통한 접근이 가능한 로드 밸런서를 외부 로드 밸런서라 부른다.

특정 로드 밸런서가 인터넷 연결은 전혀 없이 오직 내부용으로만 사용될 경우, 이를 내부 로드 밸런서라 부른다.

예를 들어, 기업용 프라이빗 서브넷에 소수의 인스턴스를 위한 로드 밸런서를 구현할 수 있다.

### 로드 밸런서의 핵심 구성 요소

> 리스너

리스너는 트래픽이 유입되는 로드 밸런서 리스너의 연결 부분에 대한 프로토콜과 포트를 정의한다.

긱 로드 밸런서는 유입 트래픽을 처리하기 위해 최소 하나 이상의 리스너가 필요하며 최대 열 개의 리스너를 지원한다.

모든 라우팅 규칙은 리스너에 정의할 수 있다. 

> 타깃 그룹과 타깃

로드 밸런서에서 타깃 그룹은 타깃 그룹을 논리적으로 그룹화한 것이다.

타깃 그룹은 로드 밸런서와 별개로 존재할 수 있으며, 필요할 때를 대비해 타깃 그룹을 먼저 생성해 놓을 수 있다.

타깃 그룹은 리전을 기반으로 하며 타깃 그룹이 있는 하나의 리전에서만 리소스를 할당할 수 있다.

타깃 그룹은 Auto Scaling 그룹과도 잘 연결된다.

> 규칙

로드 밸런서에서 규칙은 리스너와 타깃 그룹을 연결해주며, 조건과 동작으로 구성된다.

전달받은 요청이 규칙 조건에 부합하면 연관 동작이 일어난다.

규칙을 통해 특정 타깃 그룹으로 요청을 전송할 수 있다. 이를 경로 기반 규칙이라고 한다.

> 경로 기반 규칙

경로 기반 규칙을 사용할 때는 규칙 조건에 반드시 경로 패턴 포맷을 따라야 한다.

기본 설정 리슨너 생성 시 하나의 규칙이 포함되지만 이후 필요에 따라 규칙을 추가할 수 있다.

각각의 규칙은 적용의 우선 순위가 있다.

규칙 조건은 호스트 조건, 경로 조건 크게 두 가지가 있고, 전달 받은 요청이 규칙의 조건에 맞으면 그에 상응하는 동작이 취해진다.

> 헬스 체크

로드 밸런서는 기본적으로 트래픽의 효율적인 분배를 돕는 장치이지만 애플리케이션의 고가용성을 구현하는 도구이기도 하다.

고가용성을 구현하기 위해서는 헬스체크가 필요하며, 이는 타깃과 티깃 그룹이 항상 문제없이 가동될 수 있도록 미리 정의된 주기별로 타깃과 타깃 그룹의 상태를 확인하는 동작이다.

- 다양한 헬스 체크 상태 값

1. initial

로드 밸런서가 타깃 등록 과정에 있거나 타깃에 대한 초기 헬스 체크를 수행 중임.

2. Healthy

타깃은 건강함.

3. Unhealthy

타깃이 헬스체크에 반응하지 않거나 실패함.

4. Unused

타깃이 타깃그룹에 등록되지 않았고, 타깃그룹은 리스너 규칙에서 사용되지 않았거나, 타깃이 로드 밸런서를 사용할 수 없는 AZ에 존재함.

5. Draining

타깃의 등록이 해제됐고 연결 해제 절차가 진행 중임.

### 다중 AZ의 활용

Auto Scaling과 ELB를 활용해 애플리케이션을 구현할 때는 가능한 한 다중 AZ 기반으로 할 것을 권장하는데,
이는 다중 AZ가 고가용성을 구현하기 위한 기본 구조이기 때문이다.

다중 AZ 사용 시 가끔 문제가 나타나는데 대표적으로 자바 기반 애플리케이션이 실행될 때 몇 가지 이슈가 나타날 수 있다.

자바 기반 애플리케이션은 DNS에 있는 서버 IP 주소를 임시 저장하는데 이 때문에 매번 동일한 인스턴스로 트래픽을 재전송하는 문제가 생기곤한다.

이는 워크로드에 대한 적절한 분배가 안 된 탓에 인스턴스 용량의 균형이 맞지 않아서 발생하는 현상으로 크로스 존 로드 밸런싱을 통해 문제를 해결 할 수 있다.

> 크로스 존 로드 밸런싱

다중 AZ 간에 균등하게 처리 요청을 분배하는 것이며, ALB의 기본 기능이므로 사용자가 수동으로 설정할 필요는 없다.

CLB를 사용할 경우, API 또는 CLI를 이용해 로드 밸런서를 생성할 때 환경 설정을 통해 기능을 활성화 한다.
콘솔에서 로드 밸런서를 생성하는 경우에는 해당 옵션이 기본적으로 활성화 된다.

NLB의 경우 각 로드 밸런서 노드는 해당 AZ에 등록된 타깃으로만 트래픽을 배분한다. (??뭔말) 


1. B
2. C
3. B,D
4. A
5. B,C
6. D
7. A
8. D
9. B,C
10. D








